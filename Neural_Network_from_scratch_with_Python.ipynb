{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-layer Neural Network for Classification \n",
    "without the deep learning framework (only python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.  Import dependency package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "The following functions are retrieved from https://stackoverflow.com/questions/40427435/extract-images-from-idx3-ubyte-file-or-gzip-via-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_images():\n",
    "    with gzip.open('data/train-images-idx3-ubyte.gz', 'r') as f:\n",
    "        # first 4 bytes is a magic number\n",
    "        magic_number = int.from_bytes(f.read(4), 'big')\n",
    "        # second 4 bytes is the number of images\n",
    "        image_count = int.from_bytes(f.read(4), 'big')\n",
    "        # third 4 bytes is the row count\n",
    "        row_count = int.from_bytes(f.read(4), 'big')\n",
    "        # fourth 4 bytes is the column count\n",
    "        column_count = int.from_bytes(f.read(4), 'big')\n",
    "        # rest is the image pixel data, each pixel is stored as an unsigned byte\n",
    "        # pixel values are 0 to 255\n",
    "        image_data = f.read()\n",
    "        images = np.frombuffer(image_data, dtype=np.uint8)\\\n",
    "            .reshape((image_count, row_count, column_count))\n",
    "        return images\n",
    "\n",
    "\n",
    "def training_labels():\n",
    "    with gzip.open('data/train-labels-idx1-ubyte.gz', 'r') as f:\n",
    "        # first 4 bytes is a magic number\n",
    "        magic_number = int.from_bytes(f.read(4), 'big')\n",
    "        # second 4 bytes is the number of labels\n",
    "        label_count = int.from_bytes(f.read(4), 'big')\n",
    "        # rest is the label data, each label is stored as unsigned byte\n",
    "        # label values are 0 to 9\n",
    "        label_data = f.read()\n",
    "        labels = np.frombuffer(label_data, dtype=np.uint8)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = training_images()\n",
    "Y_t = training_labels()\n",
    "\n",
    "# normalization\n",
    "X_t = X_t / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Neural Network\n",
    "\n",
    "### 2.0 Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def prop(self, X):\n",
    "        return np.maximum(0, X)\n",
    "    \n",
    "    def delta(self, X):\n",
    "        return [1 for x in X if x >= 0 else 0]\n",
    "\n",
    "class LeakyReLU:\n",
    "    def __init__(self, hyper):\n",
    "        self.hyper = hyper\n",
    "        \n",
    "    def prop(self, X):\n",
    "        return np.maximum(self.hyper*X, X)\n",
    "    \n",
    "    def delta(self, X):\n",
    "        return [1 for x in X if x >= 0 else self.hyper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Layer_Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_dense:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = np.random.normal(size=(input_size, output_size))\n",
    "        self.b = np.random.normal(size=(1,output_size))\n",
    "    \n",
    "    def prop(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "    \n",
    "    def backprop(self,X):\n",
    "        pass\n",
    "    \n",
    "    def update_W(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def prop(self, X):\n",
    "        return np.exp(X)/np.sum(np.exp(X))\n",
    "    def backprop(self, Y):\n",
    "        pass\n",
    "    def delta(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Multi-Class Cross entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_entropy:\n",
    "    def prop(self, X, Y):\n",
    "        return -1 * np.log(X[:,Y])\n",
    "    \n",
    "    def backprop(self, Y):\n",
    "        pass\n",
    "    \n",
    "    def delta(self, X, Y):\n",
    "        result = []\n",
    "        for x,y in zip(X,Y):\n",
    "            result.append([ -1 * (1/x) for i,z in enumerate(x) if i == y else 0])\n",
    "        return np.ndarray(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        loss_func = Cross_entropy()\n",
    "        \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def prop(self):\n",
    "        pass\n",
    "    \n",
    "    def backprop(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        for layer in layers:\n",
    "            X = layer(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.65314647e-42 5.98890143e-85 1.90993690e-84 3.66016458e-76\n",
      "  1.00000000e+00 4.54972106e-80 5.38833821e-51 8.71449288e-23\n",
      "  2.63601421e-40 2.93865567e-13]]\n",
      "[182.69174151]\n"
     ]
    }
   ],
   "source": [
    "layer0 = Layer_dense(28*28,64)\n",
    "layer1 = Layer_dense(64,10)\n",
    "\n",
    "batch_x = x_t[0].reshape(1,-1)\n",
    "\n",
    "output0 = layer0.prop(batch_x)\n",
    "output1 = layer1.prop(output0)\n",
    "output2 = softmax(output1)\n",
    "output3 = cross_entropy(output2, y_t[0])\n",
    "\n",
    "print(output2)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "dl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
